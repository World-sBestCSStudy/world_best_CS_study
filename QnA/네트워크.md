# 네트워크

- **Q1. OSI 7계층에 대해 설명해주세요** <br>
  컴퓨터 사이에서 통신할 때 표준 프로토콜을 사용할 수 있도록 ISO에서 개발한 모델입니다. <br>
  물리, 데이터링크, 네트워크, 전송, 세션, 표현, 응용 계층으로 구성되어 있습니다. <br>
  이렇게 계층을 나눔으로써 통신이 일어나는 과정을 단계별로 파악할 수 있으며, <br>
  이상이 발생하면 어떤 계층이 문제인지를 쉽게 확인할 수 있다는 장점이 있습니다.

- **Q2. TCP와 UDP에 대해서 설명해주세요** <br>
  TCP는 연결형 서비스로 3-way handshaking 과정을 통해 연결을 진행하며 4-way handshaking 과정을 통해 연결을 해제합니다. <br>
  또한, 흐름 제어를 통해 데이터 처리 속도를 조절하며 혼잡 제어를 통해 네트워크 내의 패킷 수가 과도하게 증가하지 않도록 방지합니다. <br>
  그렇기 때문에 높은 신뢰성을 보장하지만 속도가 비교적 느리다는 단점이 있습니다. <br>
  UDP는 비연결형 서비스로 3-way handshaking을 사용하지 않기 때문에 신뢰성이 떨어지는 단점이 있습니다. <br>
  하지만 수신 여부를 확인하지 않기 때문에 속도가 빠릅니다. <br>
  이러한 특성 때문에 TCP는 신뢰성이 중요한 파일 전송과 같은 경우에 쓰이고, UDP는 실시간성이 중요한 스트리밍에 자주 사용됩니다.

- **Q3. TCP의 연결과 끊는 과정에 대해서 설명해주세요.** <br>
  우선 연결의 경우 3-way handshaking 과정으로 클라이언트가 서버로 접송을 요청하는 SYN 플래그를 보냅니다.<br>
  그 후에 서버는 SYN + ACK 플래그를 클라이언트로 응답을 보냅니다.<br>
  마지막으로 클라이언트가 SYN + ACK 플래그를 확인하고 ACK를 보내며 연결 성립이 진행됩니다. <br>
  연결 해제의 경우 연결과는 다르게 4-way handshaking 과정으로 <br>
  우선 클라이언트가 연결을 종료하겠다는 FIN 플래그를 전송합니다. <br>
  그 다음 서버는 확인 했다는 메세지로 ACK플래그를 클라이언트로 먼저 보냅니다. <br>
  서버는 닫을 준비가 다 된 후 클라이언트에게 FIN 플래그를 보내면 클라이언트는 ACK 플래그를 보내며 Time-wait 상태가 됩니다.

- **Q4. TCP의 연결 과정과 연결 종료 과정 단계가 차이나는 이유가 뭔가요?** <br>
  클라이언트가 데이터 전송을 마쳤다고 하더라도 서버는 아직 보낼 데이터가 남아 있을 수 있기 때문에 일단 FIN에 대한 ACK만 보내고, 데이터를 모두 전송한 후에 자신도 FIN 메세지를 보내기 때문입니다.

- **Q5. UDP는 항상 신뢰성을 보장하지 않나요??** <br>
  UDP를 사용하더라도 기존의 TCP가 가지고 있던 기능을 구현할 수 있습니다. 애초에 UDP는 데이터 전송을 제외한 어떤 기능도 정의되어있지 않는 프로토콜이기 때문에 프로토콜 자체적으로 봤을 땐 신뢰성을 보장하진 않습니다. <br>
  하지만 직접 순서 보장, 무결성 보장, 도착 보장 등을 개발자가 직접 구현한다면 TCP와 비슷한 수준의 기능을 가질 수 있습니다.

- **Q6. 흐름제어와 혼잡제어가 무엇인가요?** <br>
  흐름제어는 수신 측이 송신 측보다 데이터 처리 속도가 빠르면 문제가 없지만, 송신 측의 속도가 빠를 경우 문제가 생깁니다. <br>
  수신 측에서 제한된 저장 용량을 초과한 이후에 도착하는 패킷은 손실될 수 있으며, 만약 손실된다면 불필요한 추가 패킷 전송이 발생하게 됩니다. <br>
  즉, 송신 측과 수신 측의 TCP 버퍼 크기 차이로 인해 생기는 데이터 처리 속도 차이를 해결하기 위한 기법입니다. <br>
  혼잡제어는 데이터의 양이 라우터가 처리할 수 있는 양을 초과하면 초과된 데이터는 라우터가 처리하지 못합니다. <br>
  이때 송신 측에서는 라우터가 처리하지 못한 데이터를 손실 데이터로 간주하고 계속 재전송하여 네트워크를 혼잡하게 합니다. <br>
  이런 상황에 송신 측의 전송 속도를 적절히 조절하여 이러한 현상을 예방하는 기법입니다. <br>
  즉, 흐름 제어는 송수신 측 사이의 패킷 수를 제어하는 기능이라 할 수 있으며, 혼잡 제어는 네트워크 내의 패킷 수를 조절하여 네트워크의 오버플로우를 방지하는 기능입니다.

- **Q7. 흐름제어와 혼잡제어를 하는 방법이 뭐가있을까요?** <br>
  우선 흐름제어의 경우 매번 전송한 패킷에 대해 확인 응답을 받으면 다음 패킷을 전송하는 방법인 Stop and wait 방식과<br>
  수신 측에서 설정한 윈도우 크기만큼 송신 측에서 확인 응답 없이 패킷을 전송할 수 있게 하여 데이터 흐름을 동적으로 조절하는 제어 기법인 sliding window이 있습니다.<br>
  혼잡제어의 경우 처음에 패킷을 하나씩 보내고 이것이 문제없이 도착하면 window 크기를 1씩 증가시켜가며 전송하는 방법인 AIMD 방식과<br>
  윈도우의 크기를 1, 2, 4, 8, ...과 같이 지수적으로 증가시키다가 혼잡이 감지되면 윈도우 크기를 1로 줄이는 방식인 Slow Start,<br>
  혼잡한 상태가 되면 window size를 1로 줄이지 않고 반으로 줄이고 선형증가시키는 방법인 Fast Recovery 기법이 있습니다.

- **Q8. HTTP와 HTTPS에 대해서 설명해주세요** <br>
  우선 HTTP와 HTTPS는 모두 웹에서 데이터를 전송하는 데 사용되는 프로토콜입니다.<br>
  HTTP는 기본 프로토콜로, 웹 서버와 클라이언트 간에 정보를 주고받을 때 사용됩니다.<br>
  하지만 HTTP는 암호화되지 않은 텍스트 형태로 데이터를 전송하기 때문에, 제3자가 중간에서 데이터를 가로채기 쉽습니다.<br>
  이를 보완하기 위해 나온 HTTPS는 HTTP에 SSL/TLS 프로토콜을 사용하여 보안 기능을 추가한 것입니다. <br>
  이 프로토콜은 데이터를 암호화하여 전송하기 때문에, 제3자가 중간에서 정보를 가로채도 이해할 수 없게 됩니다.<br>
  따라서 HTTPS는 민감한 정보가 포함된 웹 사이트에서 권장되며, 현재 대부분의 웹 사이트는 기본적으로 HTTPS를 사용합니다.

- **Q9. HTTPS의 동작 과정이 어떻게 되나요?** <br>
  HTTPS는 대칭키 암호화와 비대칭키 암호화를 모두 사용합니다.<br>
  먼저 클라이언트와 서버간에 데이터를 암호화하기 위한 세션키를 교환하는 과정이 진행되는데 이때 비대칭키가 사용되며,<br>
  안전하게 세션키를 공유하게 되면 이후에 데이터를 교환하는 과정은 대칭키를 사용하게 됩니다. 즉, 세션키는 대칭키로 만들어집니다.

- **Q10. HTTP/1.1과 HTTP/2의 차이에 대해서 설명해주세요.** <br>
  http 1.1의 경우 기본적으로 연결 당 하나의 요청을 처리하도록 설계되었습니다.<br>
  그래서 동시 전송이 불가능하고 요청과 응답이 순차적으로 이루어지고 있습니다.<br>
  http 2.0의 경우 멀티플렉스 스트림 방식으로 한 커넥션으로 동시에 여러 개의 메세지를 주고 받을 수 있고 <br>
  응답은 순서에 상관없이 스트림으로 주고받습니다.

- **Q11. 비대칭키(공개키) 암호화와 대칭키 암호화에 대해 설명해주세요.** <br>
  대칭키는 어떤 정보를 암호화, 복호화 할 때 사용하는 키가 동일한 경우입니다. 즉, 암호화 된 정보를 전달하고 확인하기 위해서는 송수신자 둘 다 똑같은 키를 가지고 있어야 합니다. <br>
  공개키 암호화 방식에 비해 속도가 빠르다는 장점이 있지만, 키를 교환할 때 탈취 가능성이 있다는 단점이 있습니다. <br>
  공개키는 어떤 정보를 암호화, 복호화 할 때 사용하는 키가 서로 다른 경우입니다. 공개키는 외부에 공개되어 있고 비밀키는 자신만 가지고 있기 때문에 대칭키보다 비교적 안전(기밀성,인증,부인방지 제공)하지만 대칭키 암호화 방식에 비해 속도가 느린편입니다.

- **Q12. 로드 밸런싱(Load Balancing) 에 대해 말해보세요.** <br>
  로드 밸런싱은 주로 서버 구축 및 활용 시에 고려하는 서버에 가해지는 부하를 적절하게 분산시켜주는 장치 또는 기술을 뜻합니다. <br>
  처음에 구축했던 서버가 수용할 수 있는 범위보다 더 큰 트래픽으로 기존 서버를 사용할 수 없게 되는 경우가 있습니다. 이 때 서버 트래픽을 분산시키기 위해 사용합니다.

- **Q13. 서버 확장의 두 가지 방법(Scale-Up, Scale-Out) 에 대해 설명해보세요.** <br>
  Scale-Up 방식은 서버 자체의 성능을 향상시키는 것으로, 서버 CPU, RAM 등을 교체하여 서버의 성능을 향상시킵니다. <br>
  반면, Scale-Out 방식은 기존 서버와 동일하거나 낮은 서버를 여러 대 증설하여 운영하는 것을 뜻합니다. <br>
  보통 Scale-Out 방식을 사용하는데, 그 이유는 서버 성능을 향상시키는 것보다 여러 대의 서버를 증설하는 것이 비용적 측면에서 효과적이기 때문입니다.

- **Q14. 로드 밸런싱 알고리즘 중 대표적인 라운드 로빈, 최소 연결 방식 에 대해 설명해보세요.** <br>
  라운드 로빈(Round Robin) 알고리즘은 서버에 들어오는 요청들을 순서대로 돌아가면서 배정하는 알고리즘입니다. <br>
  뭐가되었든 하나씩 배정하기 때문에 여러 대의 서버 성능이 비슷하고 세션이 오래 지속되지 않는 경우에 적합합니다. <br>
  반면, 최소 연결 방식(Least Connection Method) 은 요청이 서버에 들어왔을 때 가장 연결이 적은 서버에 배정하는 알고리즘입니다. <br>
  서버 트래픽이 일정하지 않고 세션이 길어질 때 적합합니다. <br>
  이 외에도 서버마다 가중치를 매겨 가중치에 맞게 요청을 배정하는 가중 라운드 로빈 방식, 클라이언트의 IP주소를 해싱하여 분배하는 IP 해싱 방식, <br>
  서버의 현재 연결 상태와 응답 시간을 고려하여 배분하는 최소 리스폰 타임 알고리즘이 있습니다.

- **Q15. Blocking/Non-Blocking과 sync/async의 차이에 대해 설명하세요** <br>
  Blocking/Non-Blocking은 프로세스의 제어권과 관련된 개념이고, sync/async는 작업 완료 여부에 대한 개념입니다. <br>
  Blocking은 특정 작업이 실행될 때, 제어권을 함께 넘겨주며 작업이 끝나야 제어권을 돌려받고, Non-Blocking은 특정 작업에게 실행 명령만 내리고, 제어권은 곧바로 다시 돌려받습니다. <br>
  sync는 순차적으로 작업을 수행하기 때문에, 특정 작업이 완료될 때까지 대기하며 결과를 받은 뒤에 다음 작업을 수행합니다. <br>
  반면, async는 특정 작업의 완료 여부와 상관없이 다음 작업을 수행하며, 완료 순서가 보장되지 않습니다. <br>
  이와 관련해서 프로젝트를 진행하면서 가상 쓰레드를 통해 Non-Blocking 비동기 방식으로 서비스를 구현함으로써 기존의 Blocking 방식에서 발생할 수 있는 컨텍스트 스위칭 비용을 줄이고 <br>
  서비스의 처리 속도를 개선 시킨 경험이 있습니다.

- **Q16. www.google.com에 접속할 때 생기는 과정을 네트워크 관점에서 설명해 주세요.** <br>
  먼저 사용자가 브라우저에 URL을 입력하면 브라우저는 해당 URL에 대한 주소가 캐시에 있는 지 확인 후 없다면 DNS를 통해 서버의 진짜 주소(IP)를 찾습니다. <br>
  이후에 HTTP 프로토콜을 사용하여 HTTP 요청 메시지를 생성하고 TCP/IP 연결을 통해 HTTP요청이 서버로 전송되면, <br>
  서버는 HTTP 프로토콜을 활용해 HTTP 응답 메시지를 생성하여 TCP/IP 연결을 통해 요청한 컴퓨터로 전송합니다. <br>
  도착한 HTTP 응답 메시지는 웹페이지 데이터로 변환되고, 웹 브라우저에 의해 출력되어 사용자가 볼 수 있게 됩니다.
